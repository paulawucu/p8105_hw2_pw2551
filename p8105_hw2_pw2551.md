p8105_hw2_pw2551
================
Paula Wu
10/1/2021

Import the libraries:

``` r
library(tidyverse)
library(readxl)
library(lubridate)
```

## Problem 1

Since I’m going to use the file path fairly frequently later, I’d like
to define it beforehand.

``` r
file_path = "./data/Trash-Wheel-Collection-Totals-7-2020-2.xlsx"
```

Read and clean the Mr.Trash Wheel dataset:

``` r
wheels_df = 
  read_excel(file_path, range = "Mr. Trash Wheel!A2:N535") %>% 
  janitor::clean_names() %>%
  filter(!(is.na(dumpster))) %>% # filter out rows that don't have dumpster-specific data
  filter(!is.na(as.numeric(as.character(dumpster)))) %>% # filter out the last row: the grand total
  mutate(sports_balls = round(sports_balls, 0)) # round sports_balls to nearest integer
knitr::kable(wheels_df[0:5,])
```

| dumpster | month | year | date       | weight_tons | volume_cubic_yards | plastic_bottles | polystyrene | cigarette_butts | glass_bottles | grocery_bags | chip_bags | sports_balls | homes_powered |
|:---------|:------|-----:|:-----------|------------:|-------------------:|----------------:|------------:|----------------:|--------------:|-------------:|----------:|-------------:|--------------:|
| 1        | May   | 2014 | 2014-05-16 |        4.31 |                 18 |            1450 |        1820 |          126000 |            72 |          584 |      1162 |            7 |             0 |
| 2        | May   | 2014 | 2014-05-16 |        2.74 |                 13 |            1120 |        1030 |           91000 |            42 |          496 |       874 |            5 |             0 |
| 3        | May   | 2014 | 2014-05-16 |        3.45 |                 15 |            2450 |        3100 |          105000 |            50 |         1080 |      2032 |            6 |             0 |
| 4        | May   | 2014 | 2014-05-17 |        3.10 |                 15 |            2380 |        2730 |          100000 |            52 |          896 |      1971 |            6 |             0 |
| 5        | May   | 2014 | 2014-05-17 |        4.06 |                 18 |             980 |         870 |          120000 |            72 |          368 |       753 |            7 |             0 |

Read and clean precipitation data for 2018:

``` r
year_2018 = 
  read_excel(file_path, range = "2018 Precipitation!A2:B14") %>%  # only cells between A2:B14 are relevant
  janitor::clean_names() %>% 
  mutate(year = 2018)
knitr::kable(year_2018[0:10,])
```

| month | total | year |
|------:|------:|-----:|
|     1 |  0.94 | 2018 |
|     2 |  4.80 | 2018 |
|     3 |  2.69 | 2018 |
|     4 |  4.69 | 2018 |
|     5 |  9.27 | 2018 |
|     6 |  4.77 | 2018 |
|     7 | 10.20 | 2018 |
|     8 |  6.45 | 2018 |
|     9 | 10.47 | 2018 |
|    10 |  2.12 | 2018 |

Read and clean precipitation data for 2019:

``` r
year_2019 = 
  read_excel(file_path, range = "2019 Precipitation!A2:B14") %>%  # only cells between A2:B14 are relevant
  janitor::clean_names() %>% 
  mutate(year = 2019)
knitr::kable(year_2019[0:10,])
```

| month | total | year |
|------:|------:|-----:|
|     1 |  3.10 | 2019 |
|     2 |  3.64 | 2019 |
|     3 |  4.47 | 2019 |
|     4 |  1.46 | 2019 |
|     5 |  3.58 | 2019 |
|     6 |  0.42 | 2019 |
|     7 |  3.85 | 2019 |
|     8 |  2.39 | 2019 |
|     9 |  0.16 | 2019 |
|    10 |  5.45 | 2019 |

Combine previous two data sets:

``` r
# stack these two data sets together
two_years = 
  bind_rows(year_2018, year_2019) %>% 
  mutate(month = month.name[month])  # convert month to character variable
knitr::kable(two_years[8:16,])  # arbitrarily choose to show the data from Aug.2018 - Apr.2019
```

| month     | total | year |
|:----------|------:|-----:|
| August    |  6.45 | 2018 |
| September | 10.47 | 2018 |
| October   |  2.12 | 2018 |
| November  |  7.82 | 2018 |
| December  |  6.11 | 2018 |
| January   |  3.10 | 2019 |
| February  |  3.64 | 2019 |
| March     |  4.47 | 2019 |
| April     |  1.46 | 2019 |

``` r
# total precipitation 2018
tot_prcp_2018 = sum(pull(year_2018, total))

# median of sports balls in 2019
data_2019 = filter(wheels_df, year == 2019)
md = median(pull(data_2019, sports_balls))
```

#### Data description <br>

After tidying and merging data extracted from Mr. Trash Wheel data set,
I have two data frames in the end: `wheels_df` and `two_years`. <br> –
The `wheels_df` data frame has 453 rows and 14 columns, after omitting
non-dumpter specific data. Among those features, I think `weight_tons`
and `volume_cubic_yards` are important since they gave us a direct view
of how much trash Mr. Trash Wheel has collected during a day. The mean
of `weight_tons` is 3.2 tons, and the mean of `volume_cubic_yards` is
15.41 cubic yards - an impressive amount of trash has been collected by
Mr. Trash Wheel per day. <br> – The `two_years` data frame was created
by merging data from “2018 Precipitation” and “2019 Precipitation”, and
it has 24 rows and 3 columns. The variable `total`, which means total
precipitation during that month, is quite important. The mean of it is
4.34. <br> – The total precipitation during 2018 is 70.33, and the
number of sports balls in 2019 is 9. <br>

## Problem 2

*Note: for concision purpose, I set `show_col_types` equals to FALSE
every time I read a csv file* <br> <br> Read and manipulate data from
“pols-month.csv”

``` r
pols = 
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv", show_col_types = FALSE) %>% 
  separate(mon, into = c('year', 'month', 'day'), sep = "-", convert = TRUE) %>% 
  mutate(month = month.name[month])
```

How I determine the values for `president`: <br> - At first, I assume
`prez_dem` and `prez_gop` are both binary variables. However,
`unique(pull(pols, prez_gop))` shows the following result: 0, 1, 2.
There’s an extra **2**, which I assume it was due to entry error. I
pulled out entries that has a value of 2 for the variable `prez_gop`,
and it shows the following results:

``` r
filter(pols, prez_gop == 2) %>% 
  select(prez_gop, prez_dem, year, month)  # only select a few lines for concise output
```

    ## # A tibble: 5 × 4
    ##   prez_gop prez_dem  year month    
    ##      <dbl>    <dbl> <int> <chr>    
    ## 1        2        0  1974 August   
    ## 2        2        0  1974 September
    ## 3        2        0  1974 October  
    ## 4        2        0  1974 November 
    ## 5        2        0  1974 December

The table confirms my assumption that the 2’s are probably due to data
entry error, and it has the same meaning as 1’s. Due to the inaccuracy
in `prez_gop` column, I decide to use `prez_dem` to code for my
`president` column.

``` r
pols = 
  pols %>% 
  mutate(president = recode(prez_dem, `1` = "dem", `0` = "gop")) %>% 
  select(-c(prez_dem, prez_gop, day))
knitr::kable(pols[0:10,])
```

| year | month     | gov_gop | sen_gop | rep_gop | gov_dem | sen_dem | rep_dem | president |
|-----:|:----------|--------:|--------:|--------:|--------:|--------:|--------:|:----------|
| 1947 | January   |      23 |      51 |     253 |      23 |      45 |     198 | dem       |
| 1947 | February  |      23 |      51 |     253 |      23 |      45 |     198 | dem       |
| 1947 | March     |      23 |      51 |     253 |      23 |      45 |     198 | dem       |
| 1947 | April     |      23 |      51 |     253 |      23 |      45 |     198 | dem       |
| 1947 | May       |      23 |      51 |     253 |      23 |      45 |     198 | dem       |
| 1947 | June      |      23 |      51 |     253 |      23 |      45 |     198 | dem       |
| 1947 | July      |      23 |      51 |     253 |      23 |      45 |     198 | dem       |
| 1947 | August    |      23 |      51 |     253 |      23 |      45 |     198 | dem       |
| 1947 | September |      23 |      51 |     253 |      23 |      45 |     198 | dem       |
| 1947 | October   |      23 |      51 |     253 |      23 |      45 |     198 | dem       |

<br> Read and manipulate data from “snp.csv”

``` r
snp = 
  read_csv("./data/fivethirtyeight_datasets/snp.csv", show_col_types = FALSE) %>% 
  mutate(date = parse_date_time2(date, 'mdy', cutoff_2000 = 49)) %>% 
  separate(date, into = c('year', 'month', 'day'), sep = "-", convert = TRUE) %>%
  arrange(year, month) %>% 
  mutate(month = month.name[month]) %>% 
  select(-day) %>% 
  select(year, month, everything())
knitr::kable(snp[0:8,])
```

| year | month    | close |
|-----:|:---------|------:|
| 1950 | January  | 17.05 |
| 1950 | February | 17.22 |
| 1950 | March    | 17.29 |
| 1950 | April    | 17.96 |
| 1950 | May      | 18.78 |
| 1950 | June     | 17.69 |
| 1950 | July     | 17.84 |
| 1950 | August   | 18.42 |

<br> Read and manipulate data from “unemployment.csv”

``` r
unemploy =
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv", show_col_types = FALSE) %>% 
  janitor::clean_names() %>% 
  pivot_longer(jan:dec, names_to = "month", values_to = "unemploy_rate") %>% 
  filter(!(is.na(unemploy_rate))) %>% # omit NULL data after Jun 2015 
  mutate(year = as.integer(year)) %>% # change type to integer for `year`
  mutate(month = month.name[match(str_to_title(month), month.abb)])  # for consistent month names
knitr::kable(unemploy[0:10,])
```

| year | month     | unemploy_rate |
|-----:|:----------|--------------:|
| 1948 | January   |           3.4 |
| 1948 | February  |           3.8 |
| 1948 | March     |           4.0 |
| 1948 | April     |           3.9 |
| 1948 | May       |           3.5 |
| 1948 | June      |           3.6 |
| 1948 | July      |           3.6 |
| 1948 | August    |           3.9 |
| 1948 | September |           3.8 |
| 1948 | October   |           3.7 |

<br>Merge `snp` into `pols`:

``` r
merge_1 = left_join(pols, snp, by = c('year', 'month'))
merge_1 = left_join(merge_1, unemploy, by = c('year', 'month'))
```

Just for more straightforward presentation, I rearranged the data set in
the way that I think could help interpretation.

``` r
merge_1 = 
  merge_1 %>% 
  select(year, month, president, close, unemploy_rate, everything())
knitr::kable(merge_1[11:21,])  # data entries displayed here are arbitrarily selected
```

| year | month     | president | close | unemploy_rate | gov_gop | sen_gop | rep_gop | gov_dem | sen_dem | rep_dem |
|-----:|:----------|:----------|------:|--------------:|--------:|--------:|--------:|--------:|--------:|--------:|
| 1947 | November  | dem       |    NA |            NA |      24 |      51 |     253 |      23 |      45 |     198 |
| 1947 | December  | dem       |    NA |            NA |      24 |      51 |     253 |      23 |      45 |     198 |
| 1948 | January   | dem       |    NA |           3.4 |      22 |      53 |     253 |      24 |      48 |     198 |
| 1948 | February  | dem       |    NA |           3.8 |      22 |      53 |     253 |      24 |      48 |     198 |
| 1948 | March     | dem       |    NA |           4.0 |      22 |      53 |     253 |      24 |      48 |     198 |
| 1948 | April     | dem       |    NA |           3.9 |      22 |      53 |     253 |      24 |      48 |     198 |
| 1948 | May       | dem       |    NA |           3.5 |      22 |      53 |     253 |      24 |      48 |     198 |
| 1948 | June      | dem       |    NA |           3.6 |      22 |      53 |     253 |      24 |      48 |     198 |
| 1948 | July      | dem       |    NA |           3.6 |      22 |      53 |     253 |      24 |      48 |     198 |
| 1948 | August    | dem       |    NA |           3.9 |      22 |      53 |     253 |      24 |      48 |     198 |
| 1948 | September | dem       |    NA |           3.8 |      22 |      53 |     253 |      24 |      48 |     198 |

#### Data description <br>

-   `pols` is the largest data set among these three, both in dimension
    (822, 9) and in year range (from Jan.1947 to Jun.2015). After data
    tidying, it mainly contains year, month, the number of either GOP or
    Democratic governors/ senators/ representatives on a specific day,
    and the current president’s party. <br>
-   `snp` has a dimension of 787, 3. After data tidying and
    manipulation, it contains year, month, and the closing value of the
    S&P stock. <br>
-   `unemploy` has a dimension of 810, 3. It contains year, month, and
    unemployment rate of the associate month. <br>
-   All data sets have different year range. After merging, the final
    data set has a dimension of 822, 11. The year ranges from Jan.1947
    to Jun.2015, which is the same as `pols` since we used
    `left_join()`. As I did above, I rearranged the data set and put
    five variables that I think is important upfront: year, month,
    president, close, unemploy_rate.<br>
-   Please be noted that there are many NAs in both `close` and
    `unemploy_rate` columns, this is because data in `snp` and
    `umemploy` aren’t consistently populated until Jan.1950 and
    Jan.1948, respectively. Also, `snp` has a data entry for Jul.2015
    but `pols` doesn’t, and this entry is excluded due to the use of
    `left_join()`. <br>

## Problem 3

Read data, clean variable names, gender, child’s first names

``` r
baby_names = 
  read_csv("./data/Popular_Baby_Names.csv",show_col_types = FALSE) %>% 
  janitor::clean_names() %>% 
  mutate(childs_first_name = str_to_title(childs_first_name)) %>% 
  mutate(gender = str_to_lower(gender))
```

I set all values in `gender` to lower cases for a better-looking data
set. And I reformatted `childs_first_name` because there are several
entries where first names are all capitalized.<br> <br> Check for
different ethnicity values

``` r
# check different values in the variable `ethnicity`
unique(pull(baby_names, ethnicity))
```

    ## [1] "ASIAN AND PACIFIC ISLANDER" "BLACK NON HISPANIC"        
    ## [3] "HISPANIC"                   "WHITE NON HISPANIC"        
    ## [5] "ASIAN AND PACI"             "BLACK NON HISP"            
    ## [7] "WHITE NON HISP"

It’s clear that people change the ethnicity encoding overtime: “BLACK
NON HISPANIC” used to be coded as “BLACK NON HISP”, “WHITE NON HISPANIC”
used to be coded as “WHITE NON HISP”, and etc. <br> I will reformat
values in `ethnicity`, and make sure it is consistent across the data
frame.

``` r
# use find and replace
baby_names = 
  baby_names %>% 
  mutate(ethnicity = replace(ethnicity, grepl('BLACK', ethnicity), 'Black non hispanic')) %>% 
  mutate(ethnicity = replace(ethnicity, grepl('WHITE', ethnicity), 'White non hispanic')) %>%
  mutate(ethnicity = replace(ethnicity, grepl('ASIAN', ethnicity), 'Asian and pacific islander')) %>% 
  mutate(ethnicity = replace(ethnicity, grepl('HIS', ethnicity), 'Hispanic'))

# check consistency
unique(pull(baby_names, ethnicity))
```

    ## [1] "Asian and pacific islander" "Black non hispanic"        
    ## [3] "Hispanic"                   "White non hispanic"

There are only four unique values in `ethnicity`, which means I
successfully tidy the data in this column. <br> And then remove
duplicated rows:

``` r
baby_names = 
  baby_names %>% 
  distinct(year_of_birth, gender, ethnicity, childs_first_name, count, rank, .keep_all = TRUE)
knitr::kable(baby_names[0:10,])
```

| year_of_birth | gender | ethnicity                  | childs_first_name | count | rank |
|--------------:|:-------|:---------------------------|:------------------|------:|-----:|
|          2016 | female | Asian and pacific islander | Olivia            |   172 |    1 |
|          2016 | female | Asian and pacific islander | Chloe             |   112 |    2 |
|          2016 | female | Asian and pacific islander | Sophia            |   104 |    3 |
|          2016 | female | Asian and pacific islander | Emily             |    99 |    4 |
|          2016 | female | Asian and pacific islander | Emma              |    99 |    4 |
|          2016 | female | Asian and pacific islander | Mia               |    79 |    5 |
|          2016 | female | Asian and pacific islander | Charlotte         |    59 |    6 |
|          2016 | female | Asian and pacific islander | Sarah             |    57 |    7 |
|          2016 | female | Asian and pacific islander | Isabella          |    56 |    8 |
|          2016 | female | Asian and pacific islander | Hannah            |    56 |    8 |

<br> How the name *Olivia* change overtime

``` r
olivias = 
  baby_names %>% 
  filter(childs_first_name == "Olivia") %>% 
  select(-c(childs_first_name, gender, count)) %>%  # get rid of not-so-useful columns
  pivot_wider(names_from = "year_of_birth", values_from = "rank") %>% 
  select(ethnicity, sort(names(.)))
knitr::kable(olivias)
```

| ethnicity                  | 2011 | 2012 | 2013 | 2014 | 2015 | 2016 |
|:---------------------------|-----:|-----:|-----:|-----:|-----:|-----:|
| Asian and pacific islander |    4 |    3 |    3 |    1 |    1 |    1 |
| Black non hispanic         |   10 |    8 |    6 |    8 |    4 |    8 |
| Hispanic                   |   18 |   22 |   22 |   16 |   16 |   13 |
| White non hispanic         |    2 |    4 |    1 |    1 |    1 |    1 |

<br>Popular boys names across time

``` r
# search for the most popular names for boys
boys = 
  baby_names %>% 
  filter(rank == 1 & gender == "male") %>% 
  select(-c(gender, rank, count)) %>%  # get rid of not-so-useful columns 
  pivot_wider(names_from = "year_of_birth", values_from = "childs_first_name") %>% 
  select(ethnicity, sort(names(.)))
knitr::kable(boys)
```

| ethnicity                  | 2011    | 2012   | 2013   | 2014   | 2015   | 2016   |
|:---------------------------|:--------|:-------|:-------|:-------|:-------|:-------|
| Asian and pacific islander | Ethan   | Ryan   | Jayden | Jayden | Jayden | Ethan  |
| Black non hispanic         | Jayden  | Jayden | Ethan  | Ethan  | Noah   | Noah   |
| Hispanic                   | Jayden  | Jayden | Jayden | Liam   | Liam   | Liam   |
| White non hispanic         | Michael | Joseph | David  | Joseph | David  | Joseph |

<br> Plotting

``` r
male_white_16 = 
  baby_names %>% 
  filter(year_of_birth == 2016 & ethnicity == "White non hispanic" & gender == "male")
ggplot(male_white_16, aes(x = rank, y = count)) + 
  geom_point() + 
  ggtitle("Count and Rank of a Child's First Name") +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(y = "# of Children with a Name", x = "Rank of a Name")
```

![](p8105_hw2_pw2551_files/figure-gfm/unnamed-chunk-21-1.png)<!-- -->
